{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 04\n",
    "\n",
    "**Due:** 2022-03-10, 11:59 PM, as a Jupyter notebook (with related files) submitted via your repo in the course GitHub organization.  Edit the provided Solutions04 notebook with your solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Add/commit a .gitignore file in your assignments repo\n",
    "\n",
    "Python, Jupyter, and other tools we'll use in the future create auxilliary files that are useful for running scripts, modules, and notebooks locally, but that should not be tracked and shared in your repo. Git supports the use of a `.gitignore` file at the top level of a repo, identifying files or groups of files (and folders) that should be ignored by Git. This file can also be used to make Git ignore platform-specific files that aren't useful to share, like the `.DS_Store` file that the macOS Finder creates in many folders (to hold file metadata).\n",
    "\n",
    "We are providing a `.gitignore` file to use in your assignment repo. **Correctly adding and commiting the `.gitignore` file is required.** You will *lose 0.5 point if it is not done correctly*. Fortunately, it's easy to do:\n",
    "\n",
    "* Sync your copy of our LabResources folder using `git pull` (which you probably already did to get your copy of this assignment).\n",
    "* **Copy** (do not just move) the `dot-gitignore` file to the top level of your assignments repor. For me, I would put it inside my `tjl9-BDAOrg` folder, so its path would be `.../tjl9-BDAOrg/dot-gitignore'.\n",
    "* **Rename** the file to `.gitignore`. On many platforms, this will cause the file to disappear from file listings (e.g., it will vanish in a macOS Finder window, and it will not appear in a Linus `ls` file listing). Don't worry, it's still there. The leading dot makes `.gitignore` a hidden file on many platforms.\n",
    "* Use Git to add and commit the `.gitignore` file.\n",
    "\n",
    "That's it!\n",
    "\n",
    "If you use a tool (editor, IDE) that creates auxilliary files or folders in your repo that you don't want to track, feel free to **add** entries to the `.gitignore` file, directing Git not to track those files. But please do not remove entries from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enhancing the *UnivariateBayesianInference* class\n",
    "\n",
    "The assignment directory includes a `univariate_bayes.py` file that implements a `univariate_bayes` module with a single class, `UnivariateBayesianInference`; this code was introduced in Lab06.  This class is meant to be used as a **base class** that is inherited by a subclass written to solve univariate inference problems with a specific type of likelihood function and data.  Lab06 provided examples for binomial and Poisson cases.  For this problem, you will enhance the capabilities of `UnivariateBayesianInference`.\n",
    "\n",
    "Your repo also has a `binomial_poisson.py` file, also meant to be used as module, with two classes that subclass `UnivariateBayesianInference`:  `BinomialInference` and `PoissonRateInference`.  We discussed and used these classes in Lab06.  There we created instances of those classes in the same file that defined them; here, you'll import the classes from the module and work with them in your solutions notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem=1.1",
     "points=2"
    ]
   },
   "source": [
    "### Problem 1.1 (2 points):\n",
    "\n",
    "> Add code to the `__init__` method of the `UnivariateBayesianInference` class (defined in `univariate_bayes.py`) that computes the mean and standard deviation of the parameter's posterior PDF.  Store the results in two new data attributes:\n",
    "* `mean`, containing the posterior mean of the value of the parameter by quadrature\n",
    "* `std`, containing the posterior standard deviation by quadrature\n",
    "\n",
    "> You may use quadrature functions in `NumPy` or `SciPy`. Be sure to maintain comments and docstrings:  revise the module docstring to note that you have revised the module's code, and provide brief comments for the added code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem=1.2",
     "points=2"
    ]
   },
   "source": [
    "### Problem 1.2 (2 points):\n",
    "\n",
    "> Test the `mean` and `std` computations by creating one instance each of `PoissonRateInference` and `BinomialInference` in your solution notebook (with input arguments of your choosing) and comparing your quadrature-based mean and standard deviation posterior summaries with analytical formulas presented in lectures.  Do the comparison by calculating the percentage difference between the quadrature-based and formula-based results and displaying the the results and percentage differences in the notebook. Display the results with an appropriate level of precision (e.g., 2 or 3 significant digits), using Python's string formatting capability.  (See [Python String Format Cookbook – mkaz.blog](https://mkaz.blog/code/python-string-format-cookbook/) for tips on this.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inference with the Cauchy distribution\n",
    "\n",
    "In Lab06 and Problem 1 the `UnivariateBayesianInference` base class was used to numerically compute results for inferences that we can handle analytically.  But this base class can also be used for problems that are not analytically tractable.  In this problem, you'll use it to do inference with data modeled with a **Cauchy distribution**.\n",
    "\n",
    "The Cauchy distribution is a special case of the Student's $t$ distribution covered in Lec08; it corresponds to Student's $t$ with degrees of freedom parameter $\\nu=1$. It has an undefined mean and an infinite variance.  It is troublesome to work with in frequentist statistics.  Even it's maximum likelihood estimator has complicated sampling properties that pose not just computational challenges, but conceptual ones (the best frequentist methods require adopting something called the *conditional frequentist approach*, related to the likelihood principle).  In Bayesian inference, it poses no conceptual difficulties, but it must be handled numerically—which you'll do here.\n",
    "\n",
    "The Cauchy distribution is known in physics as the *Lorentzian distribution*, where in certain circumstances it describes the profile of spectral lines, and the distribution of particle mass peaks in accelerator experiments.  It also appears in problems where the ratio of two quantities with normal errors is of interest; when the quantities are uncorrelated with zero mean, the PDF for the ratio is a Cauchy distribution.  As noted above, the Student's $t$ distribution with 1 degree of freedom is a Cauchy distribution.  It also arises in geometric inference problems, as you will see in this problem.\n",
    "\n",
    "You can find basic information about the Cauchy distribution [on Wikipedia](http://en.wikipedia.org/wiki/Cauchy_distribution) and in the [NIST Engineering Statistics Handbook](http://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem=2.1",
     "points=2"
    ]
   },
   "source": [
    "### Problem 2.1 (2 points):\n",
    "\n",
    "A rod of radioactive material is a distance $d$ behind a barrier (e.g., this could be a fuel rod inside a nuclear reactor). A narrow sensor strip is on the barrier, oriented orthogonal to the rod (and not near either of its ends). The rod is at an unknown position, $x_0$, along the sensor.  The sensor records the locations of $N$ gamma rays emitted by the rod, denoted $x_i$ (for $i=1$ to $N$).  We'll assume that $d$ is small compared to the length of the sensor, so that the sensor may be considered essentially infinite in length.\n",
    "\n",
    "The geometry is shown in the following figure, oriented looking down along the rod (shown as a large dot).\n",
    "\n",
    "<img src=\"CauchyGeometry.png\"/>\n",
    "\n",
    "> Assume the rod emits gamma rays isotropically (i.e., with a uniform distribution in the angle $\\theta$; consider only angles corresponding to detectable gamma rays).  Show that the PDF for the detected location of a single gamma ray, $x$, is a Cauchy distribution with location parameter $x_0$ and scale parameter $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem=2.2",
     "points=5"
    ]
   },
   "source": [
    "### Problem 2.2 (5 points):\n",
    "\n",
    "Implement and demonstrate inference for the Cauchy location parameter, $x_0$ (using a uniform prior):\n",
    "\n",
    "> * Create a Python module `cauchy.py` with a class `CauchyLocationInference` that implements inference for the location of Cauchy-distributed data with a *known* scale parameter.\n",
    "* In the notebook, define a function with signature `cauchy_case(x0, d, N, plot=True)` that does the following:\n",
    "    1. Use `scipy.stats.cauchy` to simulate a dataset of size `N` from a Cauchy distribution with location and scale `x0` and `d`.\n",
    "    2. Create an instance of your `CauchyLocationInference` class for inferring `x0` with the simulated data.\n",
    "    3. If the `plot` argument is True, plot the PDF for `x0`.\n",
    "    4. If the `plot` argument is True, show the posterior mean for `x0` on the plot by using the computed `mean` data attribute, evaluating the PDF at that value, and plotting a marker (e.g., a large dot or diamond) on the curve just plotted in step 3.\n",
    "    5. Return 2 (scalar) values: the value of the posterior mean, and the mean value of the samples in the simulated dataset.\n",
    "* Run the function 5 times, with the same arguments, to produce a single plot with 5 example posterior PDFs. Choose values for `x0` and `d` as you wish.  Use a small sample size (say, $N=5$).  Be sure to label all plot axes in this exercise, and feel free to adjust plot parameters (axis limits, line widths, etc.) to help communicate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem=2.3",
     "points=2"
    ]
   },
   "source": [
    "### Problem 2.3 (2 points):\n",
    "\n",
    "Means of one kind or another (e.g., arithmetic or weighted) are often used to estimate parameters from a sample of measurements modeled with IID sampling uncertainties.  The **central limit theorem** (CLT) provides a motivation for this.  It shows that, for large sample sizes $N$, and when the sampling distribution has a finite variance, the sample mean has a PDF that converges to a normal distribution with a standard deviation that, importantly, *shrinks with sample size* $\\propto 1/\\sqrt{N}$.\n",
    "\n",
    "The Cauchy distribution does *not* have a finite variance; as a consequence, the CLT does not hold for the sample mean when the samples are from a Cauchy distribution.  Show this numerically:\n",
    "\n",
    "> * Run your `cauchy_case` function many times (say, 1000, but use fewer for debugging!), with `plot=False`, collecting the posterior means and the sample means in separate arrays.  Use a largish sample size, say, $N=50$ or $100$.\n",
    "* Use matplotlib's `hist` function to plot histograms of the posterior means and sample means.  Use its `density` parameter to plot the histograms normalized as piecewise-constant PDFs.  You can use the `alpha` (opacity) argument to make regions of overlap easier to discern.  Feel free to change the number of bins from the default value.\n",
    "* Plot the Cauchy PDF for a single observation as a solid curve on the same plot.\n",
    "* Comment on what the plot reveals about the behavior of the sample mean."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
